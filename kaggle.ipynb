{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d89e90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "from litellm import completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da04802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Databases\\datasetV2.csv\n",
      "Processing ./Databases\\GeneralEsportData.csv\n",
      "Processing ./Databases\\HistoricalEsportData.csv\n",
      "Processing ./Databases\\vgsales.csv\n"
     ]
    }
   ],
   "source": [
    "def generate_column_description(column_name, column_data):\n",
    "    system_message = \"You are a helpful assistant that generates brief descriptions for database columns. Given a column name and sample data, provide a comprehensive description of what the column represents, the type of data it holds, and its potential values. Return only the description and nothing else. You do not need to include special formatting or the column name in the description.\"\n",
    "    user_message = f\"Name: {column_name} Data: {column_data}\"\n",
    "\n",
    "    try:\n",
    "        # Call LiteLLM's completion function\n",
    "        response = completion(\n",
    "            model=\"ollama/llama3\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_message}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract the description from the response\n",
    "        description = response['choices'][0]['message']['content'].strip()\n",
    "        \n",
    "        return description\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating description for column {column_name}: {e}\")\n",
    "        return f\"Description for {column_name} could not be generated.\"\n",
    "\n",
    "def convert_csv_to_json(csv_file_path):\n",
    "    with open(csv_file_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        rows = list(reader)\n",
    "        columns = list(reader.fieldnames)\n",
    "                \n",
    "        # Generate column descriptions using LiteLLM\n",
    "        column_descriptions = []\n",
    "        data = [list(row.values()) for row in rows]\n",
    "        for i in range(len(columns)):\n",
    "            sampleData = []\n",
    "            for j in range(min(len(data), 10)):\n",
    "                sampleData.append(data[j][i])\n",
    "            column_descriptions.append(generate_column_description(columns[i], sampleData))\n",
    "        \n",
    "        # Put data together including all relevant data.\n",
    "        data_structure = {\n",
    "            \"name\": os.path.splitext(os.path.basename(csv_file_path))[0],\n",
    "            \"columns\": columns,\n",
    "            \"column_descriptions\": column_descriptions,\n",
    "            \"primary_key\": columns[0],\n",
    "            \"data\": data\n",
    "        }\n",
    "        \n",
    "        return data_structure\n",
    "\n",
    "# Validate datasets\n",
    "if not os.path.exists('./Databases'):\n",
    "    print(f\"Please add your files to a directory labelled 'Databases'.\")\n",
    "    raise\n",
    "\n",
    "csv_files = [f for f in os.listdir(\"./Databases\") if f.endswith('.csv')]\n",
    "\n",
    "if not csv_files:\n",
    "    print(\"No CSV files found in the directory.\")\n",
    "    raise\n",
    "\n",
    "all_tables = [] \n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    csv_file_path = os.path.join(\"./Databases\", csv_file)\n",
    "    print(f\"Processing {csv_file_path}\")\n",
    "    \n",
    "    # Convert CSV to JSON format and append it to all_tables\n",
    "    table_data = convert_csv_to_json(csv_file_path)\n",
    "    all_tables.append(table_data)\n",
    "\n",
    "# Find the next available schema file name\n",
    "x = 1\n",
    "while os.path.exists(os.path.join(\"./\", f\"schema_{x}.json\")):\n",
    "    x += 1\n",
    "output_file_path =  os.path.join(\"./\", f\"schema_{x}.json\")\n",
    "\n",
    "x_str = str(x)\n",
    "if x < 100:\n",
    "     x_str = '0' + x_str\n",
    "if x < 10:\n",
    "     x_str = '0' + x_str\n",
    "\n",
    "system_message = \"You are a helpful assistant that generates a domain based on data contained within a table. For example, a domain can be \\\"Video Games\\\", \\\"Flowers\\\", or \\\"Meteorological Patterns\\\". Given the information, you will return only the domain and nothing else. Keep the domain to 1-3 words at most.\"\n",
    "user_message = f\"Data: {all_tables}\"\n",
    "\n",
    "response = completion(\n",
    "    model=\"ollama/llama3\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": user_message}\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Extract the description from the response\n",
    "domain = response['choices'][0]['message']['content'].strip()\n",
    "\n",
    "schema_data = {\n",
    "    \"schema_id\": \"schema_r\" + x_str,\n",
    "    \"domain\": domain,\n",
    "    \"tables\": all_tables\n",
    "}\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as jsonfile:\n",
    "        json.dump(schema_data, jsonfile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
